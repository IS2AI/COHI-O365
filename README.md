# COHI-O365
We present he most diverse in number of images/labels/classes fisheye synthetic dataset with source codes and models. As well as a benchmarking testing real dataset.

COHI-O365 is a benchmark testing dataset for object detection in hemispherical/fisheye  for field of view invariant applications. It contains 1,000 real fisheye images of 74 classes sampled from the )bjects 365 dataset with 20.798 object instances per image on average. The images were captured using a hemispherical camera ELP-USB8MP02G-L180 with the 2,448 by 3,264 pixel resolution and manually annotated with standard axis-aligned bounding boxes afterward. The samples of raw and annotated images from the COHI-O365 dataset are shown below (to be inserted).

The names of sampled classes and the number of bounding boxes for each class are presented in the next figure (to be inserted).

## The Fisheye versions of Objects 365 dataset
To train object detection models for the COHI-O365 dataset, the Fisheye versions of Objects 365 dataset was generated by applying a non-linear mapping to obtain fisheye-looking images. We called it the RMFV365 dataset, comprising 5.1 million images that encompass a broad spectrum of perspectives and distortions. This dataset serves as a valuable resource for training the model in generalized object recognition tasks. The samples of raw and annotated images are illustrated below (insert!!!).

## Download the datasets
### The COHI-O365 dataset
One can access the COHI dataset using the following Google Drive link: (to be inserted)

### The FisheyeCOCO dataset
The RMFV365 dataset can be downloaded with a link: (insert!!!)


## Requirements
### For data preprocessing
* numpy
* PIL
* pandas

### For object detection
We used YOLOv7 to train and evaluate object detection models. All needed information can be found on their official GitHub page 
[YOLOv7](https://github.com/WongKinYiu/yolov7). 

## Pre-trained models
We trained the YOLOv7 model with 36.9 M parameters on three datasets (which???) and evaluated the performance of models with our benchmark testing dataset - COHI-O365).



- **YOLOv7_original**: trained on the Objects365 dataset
- **YOLOv7_transformed1**: trained on ...
- **YOLOv7_transformed2**: trained on ...



## Results

mAP<sub>50</sub> results are summarized in the table below.

(Inserts!!!!!!!!!!!!!!!!!!!!!!!!!)


Pre-trained model weights can be downloaded using a Google Drive link:  (!!!!!!!!!!!!!!!!!!!!)


## Citation

.........................



